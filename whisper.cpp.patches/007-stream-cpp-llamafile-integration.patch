--- examples/stream/stream.cpp	2025-10-31 22:21:46
+++ ../whisper.cpp.patches/stream.cpp	2025-10-31 16:01:53
@@ -1,8 +1,3 @@
-// Real-time speech recognition of input from a microphone
-//
-// A very quick-n-dirty implementation serving mainly as a proof of concept.
-//
-#include "common-sdl.h"
 #include "common.h"
 #include "whisper.h"
 
@@ -12,11 +7,11 @@
 #include <thread>
 #include <vector>
 #include <fstream>
+#include <cosmoaudio.h>
 
-
 // command-line parameters
 struct whisper_params {
-    int32_t n_threads  = std::min(4, (int32_t) std::thread::hardware_concurrency());
+    int32_t n_threads  = std::min(8, (int32_t) std::thread::hardware_concurrency());
     int32_t step_ms    = 3000;
     int32_t length_ms  = 10000;
     int32_t keep_ms    = 200;
@@ -33,7 +28,7 @@
     bool no_context    = true;
     bool no_timestamps = false;
     bool tinydiarize   = false;
-    bool save_audio    = false; // save audio to wav file
+    bool save_audio    = false;
     bool use_gpu       = true;
     bool flash_attn    = false;
 
@@ -67,7 +62,7 @@
         else if (arg == "-kc"   || arg == "--keep-context")  { params.no_context    = false; }
         else if (arg == "-l"    || arg == "--language")      { params.language      = argv[++i]; }
         else if (arg == "-m"    || arg == "--model")         { params.model         = argv[++i]; }
-        else if (arg == "-f"    || arg == "--file")          { params.fname_out     = argv[++i]; }
+        else if (arg == "-o"    || arg == "--output-file")   { params.fname_out     = argv[++i]; }
         else if (arg == "-tdrz" || arg == "--tinydiarize")   { params.tinydiarize   = true; }
         else if (arg == "-sa"   || arg == "--save-audio")    { params.save_audio    = true; }
         else if (arg == "-ng"   || arg == "--no-gpu")        { params.use_gpu       = false; }
@@ -104,7 +99,7 @@
     fprintf(stderr, "  -kc,      --keep-context  [%-7s] keep context between audio chunks\n",              params.no_context ? "false" : "true");
     fprintf(stderr, "  -l LANG,  --language LANG [%-7s] spoken language\n",                                params.language.c_str());
     fprintf(stderr, "  -m FNAME, --model FNAME   [%-7s] model path\n",                                     params.model.c_str());
-    fprintf(stderr, "  -f FNAME, --file FNAME    [%-7s] text output file name\n",                          params.fname_out.c_str());
+    fprintf(stderr, "  -o FNAME, --file FNAME    [%-7s] text output file name\n",                          params.fname_out.c_str());
     fprintf(stderr, "  -tdrz,    --tinydiarize   [%-7s] enable tinydiarize (requires a tdrz model)\n",     params.tinydiarize ? "true" : "false");
     fprintf(stderr, "  -sa,      --save-audio    [%-7s] save the recorded audio to a file\n",              params.save_audio ? "true" : "false");
     fprintf(stderr, "  -ng,      --no-gpu        [%-7s] disable GPU inference\n",                          params.use_gpu ? "false" : "true");
@@ -112,39 +107,60 @@
     fprintf(stderr, "\n");
 }
 
-int main(int argc, char ** argv) {
+struct Transcriber {
     whisper_params params;
+    bool use_vad;
+    int n_samples_step;
+    int n_samples_len;
+    int n_samples_keep;
+    int n_new_line;
+    struct CosmoAudio *audio;
+    struct whisper_context *ctx;
+    std::vector<float> pcmf32;
+    std::vector<float> pcmf32_old;
+    std::vector<float> pcmf32_new;
+    std::vector<whisper_token> prompt_tokens;
+    int n_iter;
+    std::ofstream fout;
+    wav_writer wavWriter;
 
-    if (whisper_params_parse(argc, argv, params) == false) {
+    int main(int argc, char *argv[]);
+
+    void inference();
+};
+
+int Transcriber::main(int argc, char *argv[]) {
+    if (whisper_params_parse(argc, argv, params) == false)
         return 1;
-    }
 
     params.keep_ms   = std::min(params.keep_ms,   params.step_ms);
     params.length_ms = std::max(params.length_ms, params.step_ms);
 
-    const int n_samples_step = (1e-3*params.step_ms  )*WHISPER_SAMPLE_RATE;
-    const int n_samples_len  = (1e-3*params.length_ms)*WHISPER_SAMPLE_RATE;
-    const int n_samples_keep = (1e-3*params.keep_ms  )*WHISPER_SAMPLE_RATE;
-    const int n_samples_30s  = (1e-3*30000.0         )*WHISPER_SAMPLE_RATE;
+    n_samples_step = (1e-3*params.step_ms  )*WHISPER_SAMPLE_RATE;
+    n_samples_len  = (1e-3*params.length_ms)*WHISPER_SAMPLE_RATE;
+    n_samples_keep = (1e-3*params.keep_ms  )*WHISPER_SAMPLE_RATE;
 
-    const bool use_vad = n_samples_step <= 0; // sliding window mode uses VAD
+    use_vad = n_samples_step <= 0; // sliding window mode uses VAD
 
-    const int n_new_line = !use_vad ? std::max(1, params.length_ms / params.step_ms - 1) : 1; // number of steps to print new line
+    n_new_line = !use_vad ? std::max(1, params.length_ms / params.step_ms - 1) : 1; // number of steps to print new line
 
     params.no_timestamps  = !use_vad;
     params.no_context    |= use_vad;
     params.max_tokens     = 0;
 
     // init audio
-
-    audio_async audio(params.length_ms);
-    if (!audio.init(params.capture_id, WHISPER_SAMPLE_RATE)) {
-        fprintf(stderr, "%s: audio.init() failed!\n", __func__);
-        return 1;
+    struct CosmoAudioOpenOptions cao = {};
+    cao.sizeofThis = sizeof(struct CosmoAudioOpenOptions);
+    cao.deviceType = kCosmoAudioDeviceTypeCapture;
+    cao.sampleRate = WHISPER_SAMPLE_RATE;
+    cao.bufferFrames = n_samples_len;
+    cao.channels = 1;
+    cao.debugLog = 1;
+    if (cosmoaudio_open(&audio, &cao) != COSMOAUDIO_SUCCESS) {
+        fprintf(stderr, "error: failed to open microphone\n");
+        exit(1);
     }
 
-    audio.resume();
-
     // whisper init
     if (params.language != "auto" && whisper_lang_id(params.language.c_str()) == -1){
         fprintf(stderr, "error: unknown language '%s'\n", params.language.c_str());
@@ -153,53 +169,13 @@
     }
 
     struct whisper_context_params cparams = whisper_context_default_params();
-
-    cparams.use_gpu    = params.use_gpu;
+    // cparams.use_gpu    = params.use_gpu;
     cparams.flash_attn = params.flash_attn;
 
-    struct whisper_context * ctx = whisper_init_from_file_with_params(params.model.c_str(), cparams);
+    ctx = whisper_init_from_file_with_params(params.model.c_str(), cparams);
 
-    std::vector<float> pcmf32    (n_samples_30s, 0.0f);
-    std::vector<float> pcmf32_old;
-    std::vector<float> pcmf32_new(n_samples_30s, 0.0f);
-
-    std::vector<whisper_token> prompt_tokens;
-
-    // print some info about the processing
-    {
-        fprintf(stderr, "\n");
-        if (!whisper_is_multilingual(ctx)) {
-            if (params.language != "en" || params.translate) {
-                params.language = "en";
-                params.translate = false;
-                fprintf(stderr, "%s: WARNING: model is not multilingual, ignoring language and translation options\n", __func__);
-            }
-        }
-        fprintf(stderr, "%s: processing %d samples (step = %.1f sec / len = %.1f sec / keep = %.1f sec), %d threads, lang = %s, task = %s, timestamps = %d ...\n",
-                __func__,
-                n_samples_step,
-                float(n_samples_step)/WHISPER_SAMPLE_RATE,
-                float(n_samples_len )/WHISPER_SAMPLE_RATE,
-                float(n_samples_keep)/WHISPER_SAMPLE_RATE,
-                params.n_threads,
-                params.language.c_str(),
-                params.translate ? "translate" : "transcribe",
-                params.no_timestamps ? 0 : 1);
-
-        if (!use_vad) {
-            fprintf(stderr, "%s: n_new_line = %d, no_context = %d\n", __func__, n_new_line, params.no_context);
-        } else {
-            fprintf(stderr, "%s: using VAD, will transcribe on speech activity\n", __func__);
-        }
-
-        fprintf(stderr, "\n");
-    }
-
-    int n_iter = 0;
+    n_iter = 0;
 
-    bool is_running = true;
-
-    std::ofstream fout;
     if (params.fname_out.length() > 0) {
         fout.open(params.fname_out);
         if (!fout.is_open()) {
@@ -208,7 +184,6 @@
         }
     }
 
-    wav_writer wavWriter;
     // save wav file
     if (params.save_audio) {
         // Get current date/time for filename
@@ -216,9 +191,9 @@
         char buffer[80];
         strftime(buffer, sizeof(buffer), "%Y%m%d%H%M%S", localtime(&now));
         std::string filename = std::string(buffer) + ".wav";
-
         wavWriter.open(filename, WHISPER_SAMPLE_RATE, 16, 1);
     }
+
     printf("[Start speaking]\n");
     fflush(stdout);
 
@@ -226,195 +201,163 @@
     const auto t_start = t_last;
 
     // main audio loop
-    while (is_running) {
-        if (params.save_audio) {
+    for (;;) {
+        if (params.save_audio)
             wavWriter.write(pcmf32_new.data(), pcmf32_new.size());
-        }
-        // handle Ctrl + C
-        is_running = sdl_poll_events();
+        inference();
+    }
 
-        if (!is_running) {
+    cosmoaudio_close(audio);
+    whisper_print_timings(ctx);
+    whisper_free(ctx);
+    return 0;
+}
+
+void Transcriber::inference() {
+
+    pcmf32_new.clear();
+    for (;;) {
+        int rc;
+        int avail = 2;
+        if ((rc = cosmoaudio_poll(audio, &avail, 0)) != COSMOAUDIO_SUCCESS) {
+            fprintf(stderr, "error: cosmoaudio_poll failed: %d\n", rc);
+            exit(1);
+        }
+        --avail;
+        int old_size = pcmf32_new.size();
+        pcmf32_new.resize(old_size + avail);
+        if ((rc = cosmoaudio_read(audio, &pcmf32_new[old_size], avail)) != avail) {
+            fprintf(stderr, "error: cosmoaudio_poll failed: %d (want %d)\n", rc, avail);
+            continue;
+        }
+        int new_size = pcmf32_new.size();
+        if (new_size > 2*n_samples_step) {
+            fprintf(stderr, "\n\n%s: WARNING: cannot process audio fast enough, dropping audio ...\n\n", __func__);
+            pcmf32_new.clear();
+        }
+        if (new_size >= n_samples_step) {
             break;
         }
+    }
 
-        // process new audio
+    // get audio
+    int n_samples_new = pcmf32_new.size();
+    // take up to params.length_ms audio from previous iteration
+    const int n_samples_take = std::min((int) pcmf32_old.size(), std::max(0, n_samples_keep + n_samples_len - n_samples_new));
+    // printf("processing: take = %d, new = %d, old = %d\n", n_samples_take, n_samples_new, (int) pcmf32_old.size());
+    pcmf32.resize(n_samples_new + n_samples_take);
+    for (int i = 0; i < n_samples_take; i++)
+        pcmf32[i] = pcmf32_old[pcmf32_old.size() - n_samples_take + i];
+    memcpy(pcmf32.data() + n_samples_take, pcmf32_new.data(), n_samples_new*sizeof(float));
 
-        if (!use_vad) {
-            while (true) {
-                audio.get(params.step_ms, pcmf32_new);
+    pcmf32_old = pcmf32;
 
-                if ((int) pcmf32_new.size() > 2*n_samples_step) {
-                    fprintf(stderr, "\n\n%s: WARNING: cannot process audio fast enough, dropping audio ...\n\n", __func__);
-                    audio.clear();
-                    continue;
-                }
+    // run the inference
+    {
+        whisper_full_params wparams = whisper_full_default_params(WHISPER_SAMPLING_BEAM_SEARCH);
+        wparams.print_progress   = false;
+        wparams.print_special    = params.print_special;
+        wparams.print_realtime   = false;
+        wparams.print_timestamps = !params.no_timestamps;
+        wparams.translate        = params.translate;
+        wparams.single_segment   = !use_vad;
+        wparams.max_tokens       = params.max_tokens;
+        wparams.language         = params.language.c_str();
+        wparams.n_threads        = params.n_threads;
+        wparams.audio_ctx        = params.audio_ctx;
+        wparams.tdrz_enable      = params.tinydiarize; // [TDRZ]
+        wparams.temperature_inc  = params.no_fallback ? 0.0f : wparams.temperature_inc;
+        wparams.prompt_tokens    = params.no_context ? nullptr : prompt_tokens.data();
+        wparams.prompt_n_tokens  = params.no_context ? 0       : prompt_tokens.size();
 
-                if ((int) pcmf32_new.size() >= n_samples_step) {
-                    audio.clear();
-                    break;
-                }
+        if (whisper_full(ctx, wparams, pcmf32.data(), pcmf32.size()) != 0) {
+            fprintf(stderr, "error: failed to process audio\n");
+            exit(6);
+        }
 
-                std::this_thread::sleep_for(std::chrono::milliseconds(1));
-            }
+        // print result;
+        {
+            if (!use_vad) {
+                printf("\33[2K\r");
 
-            const int n_samples_new = pcmf32_new.size();
+                // print long empty line to clear the previous line
+                printf("%s", std::string(100, ' ').c_str());
 
-            // take up to params.length_ms audio from previous iteration
-            const int n_samples_take = std::min((int) pcmf32_old.size(), std::max(0, n_samples_keep + n_samples_len - n_samples_new));
-
-            //printf("processing: take = %d, new = %d, old = %d\n", n_samples_take, n_samples_new, (int) pcmf32_old.size());
-
-            pcmf32.resize(n_samples_new + n_samples_take);
-
-            for (int i = 0; i < n_samples_take; i++) {
-                pcmf32[i] = pcmf32_old[pcmf32_old.size() - n_samples_take + i];
+                printf("\33[2K\r");
             }
 
-            memcpy(pcmf32.data() + n_samples_take, pcmf32_new.data(), n_samples_new*sizeof(float));
+            const int n_segments = whisper_full_n_segments(ctx);
+            for (int i = 0; i < n_segments; ++i) {
+                const char * text = whisper_full_get_segment_text(ctx, i);
 
-            pcmf32_old = pcmf32;
-        } else {
-            const auto t_now  = std::chrono::high_resolution_clock::now();
-            const auto t_diff = std::chrono::duration_cast<std::chrono::milliseconds>(t_now - t_last).count();
+                if (params.no_timestamps) {
+                    printf("%s", text);
+                    fflush(stdout);
 
-            if (t_diff < 2000) {
-                std::this_thread::sleep_for(std::chrono::milliseconds(100));
-
-                continue;
-            }
-
-            audio.get(2000, pcmf32_new);
-
-            if (::vad_simple(pcmf32_new, WHISPER_SAMPLE_RATE, 1000, params.vad_thold, params.freq_thold, false)) {
-                audio.get(params.length_ms, pcmf32);
-            } else {
-                std::this_thread::sleep_for(std::chrono::milliseconds(100));
-
-                continue;
-            }
-
-            t_last = t_now;
-        }
-
-        // run the inference
-        {
-            whisper_full_params wparams = whisper_full_default_params(WHISPER_SAMPLING_GREEDY);
-
-            wparams.print_progress   = false;
-            wparams.print_special    = params.print_special;
-            wparams.print_realtime   = false;
-            wparams.print_timestamps = !params.no_timestamps;
-            wparams.translate        = params.translate;
-            wparams.single_segment   = !use_vad;
-            wparams.max_tokens       = params.max_tokens;
-            wparams.language         = params.language.c_str();
-            wparams.n_threads        = params.n_threads;
-
-            wparams.audio_ctx        = params.audio_ctx;
-
-            wparams.tdrz_enable      = params.tinydiarize; // [TDRZ]
-
-            // disable temperature fallback
-            //wparams.temperature_inc  = -1.0f;
-            wparams.temperature_inc  = params.no_fallback ? 0.0f : wparams.temperature_inc;
-
-            wparams.prompt_tokens    = params.no_context ? nullptr : prompt_tokens.data();
-            wparams.prompt_n_tokens  = params.no_context ? 0       : prompt_tokens.size();
-
-            if (whisper_full(ctx, wparams, pcmf32.data(), pcmf32.size()) != 0) {
-                fprintf(stderr, "%s: failed to process audio\n", argv[0]);
-                return 6;
-            }
-
-            // print result;
-            {
-                if (!use_vad) {
-                    printf("\33[2K\r");
-
-                    // print long empty line to clear the previous line
-                    printf("%s", std::string(100, ' ').c_str());
-
-                    printf("\33[2K\r");
+                    if (params.fname_out.length() > 0) {
+                        fout << text;
+                    }
                 } else {
-                    const int64_t t1 = (t_last - t_start).count()/1000000;
-                    const int64_t t0 = std::max(0.0, t1 - pcmf32.size()*1000.0/WHISPER_SAMPLE_RATE);
+                    const int64_t t0 = whisper_full_get_segment_t0(ctx, i);
+                    const int64_t t1 = whisper_full_get_segment_t1(ctx, i);
 
-                    printf("\n");
-                    printf("### Transcription %d START | t0 = %d ms | t1 = %d ms\n", n_iter, (int) t0, (int) t1);
-                    printf("\n");
-                }
+                    std::string output = "[" + to_timestamp(t0, false) + " --> " + to_timestamp(t1, false) + "]  " + text;
 
-                const int n_segments = whisper_full_n_segments(ctx);
-                for (int i = 0; i < n_segments; ++i) {
-                    const char * text = whisper_full_get_segment_text(ctx, i);
+                    if (whisper_full_get_segment_speaker_turn_next(ctx, i)) {
+                        output += " [SPEAKER_TURN]";
+                    }
 
-                    if (params.no_timestamps) {
-                        printf("%s", text);
-                        fflush(stdout);
+                    output += "\n";
 
-                        if (params.fname_out.length() > 0) {
-                            fout << text;
-                        }
-                    } else {
-                        const int64_t t0 = whisper_full_get_segment_t0(ctx, i);
-                        const int64_t t1 = whisper_full_get_segment_t1(ctx, i);
+                    printf("%s", output.c_str());
+                    fflush(stdout);
 
-                        std::string output = "[" + to_timestamp(t0, false) + " --> " + to_timestamp(t1, false) + "]  " + text;
-
-                        if (whisper_full_get_segment_speaker_turn_next(ctx, i)) {
-                            output += " [SPEAKER_TURN]";
-                        }
-
-                        output += "\n";
-
-                        printf("%s", output.c_str());
-                        fflush(stdout);
-
-                        if (params.fname_out.length() > 0) {
-                            fout << output;
-                        }
+                    if (params.fname_out.length() > 0) {
+                        fout << output;
                     }
                 }
+            }
 
-                if (params.fname_out.length() > 0) {
-                    fout << std::endl;
-                }
+            if (params.fname_out.length() > 0) {
+                fout << std::endl;
+            }
 
-                if (use_vad) {
-                    printf("\n");
-                    printf("### Transcription %d END\n", n_iter);
-                }
+            if (use_vad) {
+                printf("\n");
+                printf("### Transcription %d END\n", n_iter);
             }
+        }
 
-            ++n_iter;
+        ++n_iter;
 
-            if (!use_vad && (n_iter % n_new_line) == 0) {
-                printf("\n");
+        if (!use_vad && (n_iter % n_new_line) == 0) {
+            printf("\n");
 
-                // keep part of the audio for next iteration to try to mitigate word boundary issues
-                pcmf32_old = std::vector<float>(pcmf32.end() - n_samples_keep, pcmf32.end());
+            // keep part of the audio for next iteration to try to mitigate word boundary issues
+            pcmf32_old = std::vector<float>(pcmf32.end() - n_samples_keep, pcmf32.end());
 
-                // Add tokens of the last full length segment as the prompt
-                if (!params.no_context) {
-                    prompt_tokens.clear();
+            // Add tokens of the last full length segment as the prompt
+            if (!params.no_context) {
+                prompt_tokens.clear();
 
-                    const int n_segments = whisper_full_n_segments(ctx);
-                    for (int i = 0; i < n_segments; ++i) {
-                        const int token_count = whisper_full_n_tokens(ctx, i);
-                        for (int j = 0; j < token_count; ++j) {
-                            prompt_tokens.push_back(whisper_full_get_token_id(ctx, i, j));
-                        }
+                const int n_segments = whisper_full_n_segments(ctx);
+                for (int i = 0; i < n_segments; ++i) {
+                    const int token_count = whisper_full_n_tokens(ctx, i);
+                    for (int j = 0; j < token_count; ++j) {
+                        prompt_tokens.push_back(whisper_full_get_token_id(ctx, i, j));
                     }
                 }
             }
-            fflush(stdout);
         }
+        fflush(stdout);
     }
+}
 
-    audio.pause();
+int main(int argc, char *argv[]) {
+    FLAG_gpu = LLAMAFILE_GPU_DISABLE;
+    llamafile_check_cpu();
+    ShowCrashReports();
 
-    whisper_print_timings(ctx);
-    whisper_free(ctx);
-
-    return 0;
+    struct Transcriber ts;
+    return ts.main(argc, argv);
 }
